"""
ä»£ç ä»“ç´¢å¼•è„šæœ¬ - å°†ä»£ç ä»“ä¸­çš„ä»£ç ç‰‡æ®µç´¢å¼•åˆ°çŸ¥è¯†åº“
"""
import sys
from pathlib import Path
import os
import hashlib

sys.path.insert(0, str(Path(__file__).parent.parent))

from typing import List, Dict, Any, Optional
from src.storage.vector_store import VectorStore


# æ”¯æŒçš„ä»£ç æ–‡ä»¶æ‰©å±•å
CODE_EXTENSIONS = {
    '.py': 'python',
    '.js': 'javascript',
    '.ts': 'typescript',
    '.jsx': 'javascript',
    '.tsx': 'typescript',
    '.go': 'go',
    '.java': 'java',
    '.rs': 'rust',
    '.cpp': 'cpp',
    '.c': 'c',
    '.h': 'c',
    '.hpp': 'cpp',
    '.rb': 'ruby',
    '.php': 'php',
    '.scala': 'scala',
    '.kt': 'kotlin',
    '.swift': 'swift',
}

# å¿½ç•¥çš„ç›®å½•
IGNORE_DIRS = {
    'node_modules', 'venv', '.venv', 'env', '.env',
    '__pycache__', '.git', '.svn', '.hg',
    'dist', 'build', 'target', 'out', 'bin',
    '.idea', '.vscode', '.pytest_cache',
    'vendor', 'packages', '.tox',
}

# å¿½ç•¥çš„æ–‡ä»¶æ¨¡å¼
IGNORE_FILES = {
    '__init__.py',  # é€šå¸¸æ˜¯ç©ºçš„æˆ–åªæœ‰å¯¼å…¥
    'setup.py',
    'conftest.py',
}


class CodeChunker:
    """ä»£ç åˆ‡åˆ†å™¨ - æŒ‰å‡½æ•°/ç±»åˆ‡åˆ†ä»£ç """
    
    def __init__(
        self,
        max_chunk_size: int = 1500,
        chunk_overlap: int = 200,
        min_chunk_size: int = 100
    ):
        self.max_chunk_size = max_chunk_size
        self.chunk_overlap = chunk_overlap
        self.min_chunk_size = min_chunk_size
    
    def chunk_file(self, file_path: str, content: str) -> List[Dict[str, Any]]:
        """
        å°†æ–‡ä»¶å†…å®¹åˆ‡åˆ†æˆå¤šä¸ªç‰‡æ®µ
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            content: æ–‡ä»¶å†…å®¹
            
        Returns:
            åˆ‡åˆ†åçš„ä»£ç ç‰‡æ®µåˆ—è¡¨
        """
        ext = Path(file_path).suffix.lower()
        language = CODE_EXTENSIONS.get(ext, 'text')
        
        # å…ˆå°è¯•æŒ‰å‡½æ•°/ç±»åˆ‡åˆ†
        chunks = self._chunk_by_structure(content, language)
        
        # å¦‚æœç»“æ„åˆ‡åˆ†å¤±è´¥æˆ–å—å¤ªå¤§ï¼Œä½¿ç”¨è¡Œåˆ‡åˆ†
        final_chunks = []
        for chunk in chunks:
            if len(chunk['content']) > self.max_chunk_size:
                # å¤§å—éœ€è¦è¿›ä¸€æ­¥åˆ‡åˆ†
                sub_chunks = self._chunk_by_lines(chunk['content'], chunk['start_line'])
                final_chunks.extend(sub_chunks)
            elif len(chunk['content']) >= self.min_chunk_size:
                final_chunks.append(chunk)
        
        # ä¸ºæ¯ä¸ªå—æ·»åŠ æ–‡ä»¶è·¯å¾„ä¿¡æ¯
        for chunk in final_chunks:
            chunk['file_path'] = file_path
            chunk['language'] = language
            chunk['id'] = self._generate_chunk_id(file_path, chunk['start_line'])
        
        return final_chunks
    
    def _chunk_by_structure(self, content: str, language: str) -> List[Dict[str, Any]]:
        """æŒ‰ä»£ç ç»“æ„åˆ‡åˆ†ï¼ˆå‡½æ•°ã€ç±»ç­‰ï¼‰"""
        chunks = []
        lines = content.split('\n')
        
        if language == 'python':
            chunks = self._chunk_python(lines)
        else:
            # å…¶ä»–è¯­è¨€ä½¿ç”¨é€šç”¨åˆ‡åˆ†
            chunks = self._chunk_generic(lines)
        
        return chunks
    
    def _chunk_python(self, lines: List[str]) -> List[Dict[str, Any]]:
        """Python ä»£ç åˆ‡åˆ†"""
        chunks = []
        current_chunk_lines = []
        current_start_line = 1
        in_class_or_func = False
        indent_level = 0
        
        for i, line in enumerate(lines, 1):
            stripped = line.strip()
            
            # æ£€æµ‹å‡½æ•°æˆ–ç±»å®šä¹‰
            if stripped.startswith(('def ', 'class ', 'async def ')):
                # ä¿å­˜ä¹‹å‰çš„å—
                if current_chunk_lines and len('\n'.join(current_chunk_lines)) >= self.min_chunk_size:
                    chunks.append({
                        'content': '\n'.join(current_chunk_lines),
                        'start_line': current_start_line,
                        'end_line': i - 1,
                        'type': 'function' if 'def ' in '\n'.join(current_chunk_lines) else 'code'
                    })
                
                current_chunk_lines = [line]
                current_start_line = i
                in_class_or_func = True
                indent_level = len(line) - len(line.lstrip())
            
            elif in_class_or_func:
                current_chunk_lines.append(line)
                
                # æ£€æµ‹å—æ˜¯å¦ç»“æŸï¼ˆé‡åˆ°åŒçº§æˆ–æ›´ä½ç¼©è¿›çš„éç©ºè¡Œï¼‰
                if stripped and not stripped.startswith('#'):
                    current_indent = len(line) - len(line.lstrip())
                    if current_indent <= indent_level and not stripped.startswith(('def ', 'class ', 'async def ', '@')):
                        # å—ç»“æŸ
                        if len('\n'.join(current_chunk_lines)) >= self.min_chunk_size:
                            chunks.append({
                                'content': '\n'.join(current_chunk_lines[:-1]),
                                'start_line': current_start_line,
                                'end_line': i - 1,
                                'type': 'function'
                            })
                        current_chunk_lines = [line]
                        current_start_line = i
                        in_class_or_func = False
            else:
                current_chunk_lines.append(line)
        
        # ä¿å­˜æœ€åä¸€ä¸ªå—
        if current_chunk_lines and len('\n'.join(current_chunk_lines)) >= self.min_chunk_size:
            chunks.append({
                'content': '\n'.join(current_chunk_lines),
                'start_line': current_start_line,
                'end_line': len(lines),
                'type': 'code'
            })
        
        return chunks if chunks else [{'content': '\n'.join(lines), 'start_line': 1, 'end_line': len(lines), 'type': 'file'}]
    
    def _chunk_generic(self, lines: List[str]) -> List[Dict[str, Any]]:
        """é€šç”¨ä»£ç åˆ‡åˆ†"""
        # ç®€å•æŒ‰è¡Œæ•°åˆ‡åˆ†
        content = '\n'.join(lines)
        return [{
            'content': content,
            'start_line': 1,
            'end_line': len(lines),
            'type': 'file'
        }]
    
    def _chunk_by_lines(self, content: str, base_line: int = 1) -> List[Dict[str, Any]]:
        """æŒ‰è¡Œæ•°åˆ‡åˆ†å¤§å—"""
        chunks = []
        lines = content.split('\n')
        
        # è®¡ç®—æ¯å—å¤§çº¦å¤šå°‘è¡Œ
        avg_line_length = len(content) / max(len(lines), 1)
        lines_per_chunk = int(self.max_chunk_size / max(avg_line_length, 1))
        lines_per_chunk = max(lines_per_chunk, 20)  # è‡³å°‘20è¡Œ
        
        overlap_lines = int(self.chunk_overlap / max(avg_line_length, 1))
        
        start = 0
        while start < len(lines):
            end = min(start + lines_per_chunk, len(lines))
            chunk_lines = lines[start:end]
            chunk_content = '\n'.join(chunk_lines)
            
            if len(chunk_content) >= self.min_chunk_size:
                chunks.append({
                    'content': chunk_content,
                    'start_line': base_line + start,
                    'end_line': base_line + end - 1,
                    'type': 'chunk'
                })
            
            start = end - overlap_lines if end < len(lines) else end
        
        return chunks
    
    def _generate_chunk_id(self, file_path: str, start_line: int) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„ chunk ID"""
        content = f"{file_path}:{start_line}"
        return hashlib.md5(content.encode()).hexdigest()[:16]


class CodeIndexer:
    """ä»£ç ç´¢å¼•å™¨"""
    
    def __init__(
        self,
        vector_store: VectorStore,
        chunker: Optional[CodeChunker] = None
    ):
        self.vector_store = vector_store
        self.chunker = chunker or CodeChunker()
    
    def index_repository(
        self,
        repo_path: str,
        include_patterns: Optional[List[str]] = None,
        exclude_patterns: Optional[List[str]] = None
    ) -> Dict[str, int]:
        """
        ç´¢å¼•æ•´ä¸ªä»£ç ä»“
        
        Args:
            repo_path: ä»“åº“è·¯å¾„
            include_patterns: åŒ…å«çš„æ–‡ä»¶æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
            exclude_patterns: æ’é™¤çš„æ–‡ä»¶æ¨¡å¼ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            ç´¢å¼•ç»Ÿè®¡
        """
        repo_path = Path(repo_path)
        if not repo_path.exists():
            raise ValueError(f"ä»“åº“è·¯å¾„ä¸å­˜åœ¨: {repo_path}")
        
        stats = {
            'files_scanned': 0,
            'files_indexed': 0,
            'chunks_created': 0,
            'errors': 0
        }
        
        # éå†æ‰€æœ‰ä»£ç æ–‡ä»¶
        for file_path in self._find_code_files(repo_path):
            stats['files_scanned'] += 1
            
            try:
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                
                # è·³è¿‡ç©ºæ–‡ä»¶æˆ–å¤ªå¤§çš„æ–‡ä»¶
                if not content.strip() or len(content) > 100000:
                    continue
                
                # åˆ‡åˆ†ä»£ç 
                rel_path = str(file_path.relative_to(repo_path))
                chunks = self.chunker.chunk_file(rel_path, content)
                
                if chunks:
                    # ç´¢å¼•åˆ°å‘é‡æ•°æ®åº“
                    self._index_chunks(chunks)
                    stats['files_indexed'] += 1
                    stats['chunks_created'] += len(chunks)
                    
                    print(f"  âœ“ {rel_path} ({len(chunks)} chunks)")
                    
            except Exception as e:
                stats['errors'] += 1
                print(f"  âœ— {file_path}: {e}")
        
        return stats
    
    def _find_code_files(self, repo_path: Path) -> List[Path]:
        """æŸ¥æ‰¾æ‰€æœ‰ä»£ç æ–‡ä»¶"""
        code_files = []
        
        for root, dirs, files in os.walk(repo_path):
            # è¿‡æ»¤å¿½ç•¥çš„ç›®å½•
            dirs[:] = [d for d in dirs if d not in IGNORE_DIRS and not d.startswith('.')]
            
            for file in files:
                if file in IGNORE_FILES:
                    continue
                
                file_path = Path(root) / file
                ext = file_path.suffix.lower()
                
                if ext in CODE_EXTENSIONS:
                    code_files.append(file_path)
        
        return code_files
    
    def _index_chunks(self, chunks: List[Dict[str, Any]]):
        """å°†ä»£ç ç‰‡æ®µç´¢å¼•åˆ°å‘é‡æ•°æ®åº“"""
        snippets = []
        for chunk in chunks:
            snippets.append({
                'id': chunk['id'],
                'content': chunk['content'],
                'metadata': {
                    'file_path': chunk['file_path'],
                    'language': chunk['language'],
                    'start_line': chunk['start_line'],
                    'end_line': chunk['end_line'],
                    'type': chunk.get('type', 'code')
                }
            })
        
        self.vector_store.add_code_snippets(snippets)


def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='ç´¢å¼•ä»£ç ä»“åˆ°çŸ¥è¯†åº“')
    parser.add_argument('repo_path', nargs='?', help='ä»£ç ä»“è·¯å¾„')
    parser.add_argument('--clear', action='store_true', help='æ¸…ç©ºç°æœ‰ä»£ç ç´¢å¼•')
    args = parser.parse_args()
    
    # ä»ç¯å¢ƒå˜é‡æˆ–å‚æ•°è·å–è·¯å¾„
    repo_path = args.repo_path
    if not repo_path:
        from config.settings import settings
        repo_path = settings.code_repo_path
    
    if not repo_path:
        print("âŒ è¯·æŒ‡å®šä»£ç ä»“è·¯å¾„:")
        print("   python scripts/index_code_repo.py /path/to/copilot-server")
        print("   æˆ–åœ¨ .env ä¸­è®¾ç½® CODE_REPO_PATH")
        sys.exit(1)
    
    print(f"ğŸš€ ç´¢å¼•ä»£ç ä»“: {repo_path}\n")
    
    # åˆå§‹åŒ–
    vector_store = VectorStore(persist_directory="./data/chroma")
    
    # æ¸…ç©ºç°æœ‰ç´¢å¼•
    if args.clear:
        print("ğŸ—‘ï¸  æ¸…ç©ºç°æœ‰ä»£ç ç´¢å¼•...")
        vector_store.clear_collection("code_snippets")
    
    # ç´¢å¼•ä»£ç 
    indexer = CodeIndexer(vector_store)
    stats = indexer.index_repository(repo_path)
    
    # æ‰“å°ç»Ÿè®¡
    print(f"\nğŸ“Š ç´¢å¼•å®Œæˆ:")
    print(f"   - æ‰«ææ–‡ä»¶: {stats['files_scanned']}")
    print(f"   - ç´¢å¼•æ–‡ä»¶: {stats['files_indexed']}")
    print(f"   - åˆ›å»ºç‰‡æ®µ: {stats['chunks_created']}")
    print(f"   - é”™è¯¯: {stats['errors']}")
    
    # æ€»ä½“ç»Ÿè®¡
    all_stats = vector_store.get_stats()
    print(f"\nğŸ“š çŸ¥è¯†åº“æ€»è®¡:")
    print(f"   - ä»£ç ç‰‡æ®µ: {all_stats['code_snippets']}")
    print(f"   - å†å² Case: {all_stats['history_cases']}")
    print(f"   - æ—¥å¿—æ¨¡å¼: {all_stats['log_patterns']}")


if __name__ == "__main__":
    main()
